{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow101.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/davidderaedt/ML-training/blob/master/tensorflow101.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "OBh3GupZOvFV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First let's check we can actually run python code"
      ]
    },
    {
      "metadata": {
        "id": "moj2naInCahZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b15bec3a-2441-4cf5-8004-05f1b44cc3ad"
      },
      "cell_type": "code",
      "source": [
        "print (\"hello world\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello world\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dRmSy3PdO3-X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's see if we can use tensorflow. With tensorflow you typically describe a graph which you'll then compute in a session"
      ]
    },
    {
      "metadata": {
        "id": "7chO69oZCck8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30a451ad-4518-4ce3-f344-58f3dd59bab7"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "message = tf.constant(\"hello tensorflow\")\n",
        "\n",
        "output = sess.run(message)\n",
        "\n",
        "print(output)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello tensorflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wPmMeUn3coLA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this exercise we're going to create our first model which goal is to understand the (linear) relationship between an input (our features, noted x) and an output (our labels, noted y) values in a dataset.\n",
        "\n",
        "For this example we'll make up these values and relationship ourselves."
      ]
    },
    {
      "metadata": {
        "id": "za2QBEzOdHMd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_data = [1,2,3,4]\n",
        "label_data = [11,21,31,41]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YtTqRp-BdPyJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can build our model, starting by describing the graph. We'll then train it in order for it to estimate the values of w and b.\n",
        "\n",
        "First we'll declare the two variables we're looking for : our weight (w) and bias (b), and initiate them randomly.\n",
        "\n",
        "We'll also declare placeholders for the values of our features (x) and labels (y) coming from our dataset."
      ]
    },
    {
      "metadata": {
        "id": "V9xb7-jWgBMD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w = tf.Variable([3.0], tf.float32) # holds weight (init with randomly chosen value)\n",
        "b = tf.Variable([-3.0], tf.float32) # holds bias (init with randomly chosen value)\n",
        "x = tf.placeholder(tf.float32) # will hold inputs (features)\n",
        "labels = tf.placeholder(tf.float32) # will hold labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16KPVgH2gEqW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next we'll describe how the model is supposed to estimate an output value.\n",
        "Here, it's a simple linear model, ie $y=m x + p$\n",
        "Remember we're just describing the computation here, we're not running anything (yet)."
      ]
    },
    {
      "metadata": {
        "id": "WddTESbXgnTW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_output = w * x + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_6BY87GgpZW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we'll describe how to compute the loss, ie how good or bad we did at estimating the output value. We simply compute the difference between the outputs and the labels, and come up with a single number."
      ]
    },
    {
      "metadata": {
        "id": "Jp0e8TysiZju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "delta = model_output-labels\n",
        "squared_delta = tf.square(delta)\n",
        "loss_calc = tf.reduce_sum(squared_delta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n5PHFbdmidVM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, we'll describe how to use a built-in gradient descent implementation to update w and b and hopefully reduce the cost."
      ]
    },
    {
      "metadata": {
        "id": "MmA_5zx8i0Wr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "train = optimizer.minimize(loss_calc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fF9zuXwSi29r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We're done with the description. Now we can actually run the graph, train our model, and check the result."
      ]
    },
    {
      "metadata": {
        "id": "vQ_joO0GC9Hf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f9d2b228-a5f2-446b-b965-100803bbdd24"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "\n",
        "    #First init what we declared earlier\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    #train, ie run and optimize our model a number of times\n",
        "    for i in range(1000):\n",
        "            sess.run(train, {x:input_data, labels:label_data})\n",
        "\n",
        "    #Training is done, now display values for w and b\n",
        "    print(\"Training done\")\n",
        "    print(\"W: %s\" % w.eval())\n",
        "    print(\"b: %s\" % b.eval())\n",
        "          \n",
        "    \n",
        "print(\"DONE - session closed\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training done\n",
            "W: [10.000005]\n",
            "b: [0.9999868]\n",
            "DONE - session closed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E-SA83PXOr_Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And we're done with this introduction. You can check the whole code put together below."
      ]
    },
    {
      "metadata": {
        "id": "U_Wq55JOjPIN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "input_data = [1,2,3,4]\n",
        "label_data = [11,21,31,41]\n",
        "\n",
        "w = tf.Variable([3.0], tf.float32) \n",
        "b = tf.Variable([-3.0], tf.float32) \n",
        "x = tf.placeholder(tf.float32) \n",
        "labels = tf.placeholder(tf.float32) \n",
        "\n",
        "model_output = w * x + b\n",
        "\n",
        "delta = model_output-labels\n",
        "squared_delta = tf.square(delta)\n",
        "loss_calc = tf.reduce_sum(squared_delta)\n",
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "train = optimizer.minimize(loss_calc)\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    for i in range(1000):\n",
        "            sess.run(train, {x:input_data, labels:label_data})\n",
        "\n",
        "    print(\"Training done, W and b :\")\n",
        "    print(w.eval())\n",
        "    print(b.eval())\n",
        "\n",
        "print (\"DONE - session closed\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}